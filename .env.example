# AuraOS Environment Configuration

# ============================================
# AI Provider Configuration
# ============================================

# Choose AI provider: 'anthropic' or 'vllm'
AI_PROVIDER=anthropic

# ============================================
# Anthropic Configuration (if using Anthropic)
# ============================================

# Anthropic API Key (required for Anthropic provider)
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ============================================
# vLLM Configuration (if using vLLM)
# ============================================

# vLLM Server URL (default: http://localhost:8000/v1)
VLLM_URL=http://localhost:8000/v1

# vLLM Model Name (default: meta-llama/Llama-3.1-8B-Instruct)
# Other options:
# - meta-llama/Llama-3.1-70B-Instruct (requires more GPU memory)
# - mistralai/Mistral-7B-Instruct-v0.3
# - Qwen/Qwen2.5-7B-Instruct
# - microsoft/Phi-3-mini-4k-instruct
VLLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Hugging Face Token (optional, required for gated models)
# Get your token from: https://huggingface.co/settings/tokens
# HUGGING_FACE_HUB_TOKEN=your-hf-token-here

# ============================================
# MCP Gateway Configuration
# ============================================

# Maximum number of MCP servers
MCP_MAX_SERVERS=10

# Request timeout in milliseconds
MCP_REQUEST_TIMEOUT=30000

# Enable MCP logging
MCP_ENABLE_LOGGING=true

# ============================================
# File System Configuration
# ============================================

# Root path for file system operations
FS_ROOT_PATH=/tmp/auraos-workspace

# Maximum file size in bytes (10MB default)
FS_MAX_FILE_SIZE=10485760

# ============================================
# Development Configuration
# ============================================

# Node environment
NODE_ENV=development

# API port
PORT=3000

# Enable debug logging
DEBUG=false
