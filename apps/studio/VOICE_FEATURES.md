# Voice-First Features for AuraOS Studio

## نظرة عامة

تم إضافة ميزات الصوت كواجهة أولى لـ AuraOS Studio، مما يسمح للمستخدمين بالتفاعل مع النظام عبر الكلام بدلاً من الكتابة فقط.

## الميزات المضافة

### 1. VoiceDock Component
- واجهة صوتية رئيسية مع زر تسجيل
- عرض النص الحي والنهائي
- إعدادات المحرك واللغة
- تحكم في TTS (Text-to-Speech)

### 2. Speech-to-Text (STT)
- **Whisper المحلي**: تشغيل محلي باستخدام WebAssembly
- **Deepgram السحابي**: خدمة سحابية للتعرف على الكلام
- آلية Fallback تلقائية بين المحركين

### 3. Text-to-Speech (TTS)
- **ElevenLabs**: خدمة TTS سحابية
- دعم الأصوات العربية والإنجليزية
- تحكم في الحجم والسرعة

### 4. Intent Recognition
- تحديد نية المستخدم من النص
- ربط الأوامر الصوتية بالإجراءات
- دعم الأوامر العربية والإنجليزية

### 5. Context Propagation Engine (CPE)
- تتبع السياق الحالي للمستخدم
- ربط النوايا بالسياق المناسب
- تحليل المحتوى وتقديم اقتراحات

## التدفق الكامل

```
1. المستخدم يضغط على زر الميكروفون
2. النظام يبدأ التسجيل (Whisper محلي أو Deepgram سحابي)
3. النص يظهر حياً أثناء التسجيل
4. عند التوقف، يتم معالجة النص النهائي
5. Intent Router يحدد نية المستخدم
6. يتم تنفيذ الإجراء المناسب (ملاحظة، أمر، شرح)
7. النظام يرد صوتياً عبر TTS (اختياري)
```

## الأوامر المدعومة

### أوامر التنفيذ
- "شغّل الكود" / "run code"
- "نفّذ الأمر" / "execute command"
- "تشغيل الملف" / "run file"

### أوامر الملاحظات
- "دوّن فكرة" / "write note"
- "سجّل ملاحظة" / "record note"
- "اكتب" / "write"

### أوامر الشرح
- "اشرح الكود" / "explain code"
- "وضّح الخطأ" / "clarify error"
- "ما هو" / "what is"

## الإعداد

### 1. متغيرات البيئة
```bash
# انسخ ملف env.example إلى .env
cp env.example .env

# أضف مفاتيح API الخاصة بك
REACT_APP_DEEPGRAM_API_KEY=your_deepgram_key
REACT_APP_ELEVENLABS_API_KEY=your_elevenlabs_key
```

### 2. تثبيت التبعيات
```bash
npm install
# أو
pnpm install
```

### 3. تشغيل التطبيق
```bash
npm run dev
# أو
pnpm dev
```

## البنية التقنية

```
src/
├── voice/
│   ├── types.ts              # أنواع البيانات
│   ├── VoiceController.ts    # تحكم رئيسي
│   ├── stt/
│   │   ├── deepgramClient.ts # STT سحابي
│   │   └── whisperWasmClient.ts # STT محلي
│   └── tts/
│       └── elevenlabsClient.ts # TTS سحابي
├── intent/
│   └── intentRouter.ts       # معالج النوايا
├── state/
│   └── voiceStore.ts         # حالة الصوت
└── components/
    └── VoiceDock.tsx         # واجهة الصوت
```

## التطوير المستقبلي

### Sprint 2: تحسينات الأداء
- تحسين أداء Whisper WASM
- إضافة VAD (Voice Activity Detection) متقدم
- تحسين دقة التعرف على اللهجات العربية

### Sprint 3: ميزات متقدمة
- دعم الأوامر المعقدة
- تكامل مع AI Assistant
- حفظ تفضيلات الصوت

### Sprint 4: تحسينات UX
- واجهة صوتية محسنة
- إحصائيات الاستخدام
- تخصيص الأصوات

## استكشاف الأخطاء

### مشاكل الميكروفون
- تأكد من السماح بالوصول للميكروفون
- تحقق من إعدادات المتصفح
- جرب متصفحات مختلفة

### مشاكل API
- تحقق من صحة مفاتيح API
- تأكد من اتصال الإنترنت للخدمات السحابية
- راجع logs المتصفح للأخطاء

### مشاكل الأداء
- استخدم Whisper المحلي للأداء الأفضل
- قلل من طول التسجيلات
- تأكد من إغلاق التطبيقات الأخرى

## الدعم

للحصول على الدعم أو الإبلاغ عن مشاكل:
1. راجع logs المتصفح
2. تحقق من إعدادات API
3. تأكد من دعم المتصفح للميزات المطلوبة
